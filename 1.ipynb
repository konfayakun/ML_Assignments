{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment1_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "RvEGPUF8tiOE",
        "colab_type": "code",
        "outputId": "22de65f2-5258-457e-8da1-e44545e31b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-plot\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/da/d0/95c6e93a4db54b8e6b2c2514b84838aa9f1f0f25d15eccac908fe5266831/tensorflow-plot-0.3.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-plot) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-plot) (1.16.3)\n",
            "Collecting biwrap==0.1.6 (from tensorflow-plot)\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/54/78d4d5459d7385f90908185641647ff2e8ed4a4b5c239976f78e26888679/biwrap-0.1.6.tar.gz\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-plot) (3.0.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->tensorflow-plot) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->tensorflow-plot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->tensorflow-plot) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->tensorflow-plot) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->tensorflow-plot) (40.9.0)\n",
            "Building wheels for collected packages: tensorflow-plot, biwrap\n",
            "  Building wheel for tensorflow-plot (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/39/07/7e/0a568d2f3ee877bc2f09281042ab659a8bde5fd66081a2689d\n",
            "  Building wheel for biwrap (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e5/d9/4a/0c3162411bad4df21befe385cea5bb26458ebb1aa9b2e1c13e\n",
            "Successfully built tensorflow-plot biwrap\n",
            "Installing collected packages: biwrap, tensorflow-plot\n",
            "Successfully installed biwrap-0.1.6 tensorflow-plot-0.3.0\n",
            "--2019-04-30 21:00:00--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.22.236.254, 52.3.53.115, 34.226.180.131, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.22.236.254|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14991793 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.30M  38.1MB/s    in 0.4s    \n",
            "\n",
            "2019-04-30 21:00:01 (38.1 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14991793/14991793]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Q_60a2ktkcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2j8bEAUtkT5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AIs4HRwVttbC",
        "colab_type": "code",
        "outputId": "df3a9b77-de24-4424-857c-1a3cac045c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://98703488.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4dwAH8AUZ7Rj",
        "colab_type": "code",
        "outputId": "fd4c1cdd-c281-4c8a-c672-3edeb6d026d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "#if using Theano with GPU\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from keras import applications\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras import applications\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import os\n",
        "from shutil import move\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HSWAhduFGbGn",
        "colab_type": "code",
        "outputId": "9fb9bdbf-f592-4066-fd38-214521ec230f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "!echo \"Downloading 101_Object_Categories for image notebooks\"\n",
        "!curl -L -o 101_ObjectCategories.tar.gz --progress-bar http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n",
        "!tar -xzf 101_ObjectCategories.tar.gz\n",
        "!rm 101_ObjectCategories.tar.gz\n",
        "\n",
        "!rm -rf train\n",
        "!rm -rf validation\n",
        "# create base folders\n",
        "os.mkdir('train')\n",
        "os.mkdir('validation')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 101_Object_Categories for image notebooks\n",
            "######################################################################## 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EFrZWaLxGhhD",
        "colab_type": "code",
        "outputId": "9d65ea81-d14b-4278-f517-5a09dbfb6a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "root = '101_ObjectCategories'\n",
        "# exclude = ['BACKGROUND_Google', 'Motorbikes', 'airplanes', 'Faces_easy', 'Faces']\n",
        "# train_split, val_split = 0.7, 0.15\n",
        "# \n",
        "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
        "# categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]\n",
        "# categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]\n",
        "for category in categories:\n",
        "  label= category.split('/')[1];\n",
        "  os.mkdir('./train'+os.sep+label)\n",
        "  os.mkdir('./validation'+os.sep+label)\n",
        "\n",
        "print(categories)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['101_ObjectCategories/stop_sign', '101_ObjectCategories/gramophone', '101_ObjectCategories/BACKGROUND_Google', '101_ObjectCategories/ceiling_fan', '101_ObjectCategories/watch', '101_ObjectCategories/helicopter', '101_ObjectCategories/scorpion', '101_ObjectCategories/scissors', '101_ObjectCategories/Faces', '101_ObjectCategories/water_lilly', '101_ObjectCategories/sunflower', '101_ObjectCategories/car_side', '101_ObjectCategories/rooster', '101_ObjectCategories/mandolin', '101_ObjectCategories/trilobite', '101_ObjectCategories/brain', '101_ObjectCategories/crocodile', '101_ObjectCategories/sea_horse', '101_ObjectCategories/ibis', '101_ObjectCategories/Leopards', '101_ObjectCategories/accordion', '101_ObjectCategories/camera', '101_ObjectCategories/grand_piano', '101_ObjectCategories/Motorbikes', '101_ObjectCategories/chair', '101_ObjectCategories/umbrella', '101_ObjectCategories/joshua_tree', '101_ObjectCategories/gerenuk', '101_ObjectCategories/binocular', '101_ObjectCategories/pagoda', '101_ObjectCategories/flamingo_head', '101_ObjectCategories/emu', '101_ObjectCategories/dalmatian', '101_ObjectCategories/bonsai', '101_ObjectCategories/rhino', '101_ObjectCategories/inline_skate', '101_ObjectCategories/saxophone', '101_ObjectCategories/flamingo', '101_ObjectCategories/cannon', '101_ObjectCategories/chandelier', '101_ObjectCategories/minaret', '101_ObjectCategories/dragonfly', '101_ObjectCategories/cougar_body', '101_ObjectCategories/cellphone', '101_ObjectCategories/revolver', '101_ObjectCategories/dolphin', '101_ObjectCategories/ketch', '101_ObjectCategories/laptop', '101_ObjectCategories/buddha', '101_ObjectCategories/mayfly', '101_ObjectCategories/butterfly', '101_ObjectCategories/elephant', '101_ObjectCategories/starfish', '101_ObjectCategories/beaver', '101_ObjectCategories/dollar_bill', '101_ObjectCategories/tick', '101_ObjectCategories/cougar_face', '101_ObjectCategories/metronome', '101_ObjectCategories/wrench', '101_ObjectCategories/platypus', '101_ObjectCategories/garfield', '101_ObjectCategories/ferry', '101_ObjectCategories/pyramid', '101_ObjectCategories/stegosaurus', '101_ObjectCategories/hawksbill', '101_ObjectCategories/airplanes', '101_ObjectCategories/windsor_chair', '101_ObjectCategories/euphonium', '101_ObjectCategories/hedgehog', '101_ObjectCategories/crocodile_head', '101_ObjectCategories/ant', '101_ObjectCategories/llama', '101_ObjectCategories/stapler', '101_ObjectCategories/yin_yang', '101_ObjectCategories/lotus', '101_ObjectCategories/pigeon', '101_ObjectCategories/barrel', '101_ObjectCategories/Faces_easy', '101_ObjectCategories/snoopy', '101_ObjectCategories/schooner', '101_ObjectCategories/headphone', '101_ObjectCategories/lobster', '101_ObjectCategories/electric_guitar', '101_ObjectCategories/okapi', '101_ObjectCategories/wheelchair', '101_ObjectCategories/cup', '101_ObjectCategories/menorah', '101_ObjectCategories/brontosaurus', '101_ObjectCategories/lamp', '101_ObjectCategories/crayfish', '101_ObjectCategories/bass', '101_ObjectCategories/kangaroo', '101_ObjectCategories/panda', '101_ObjectCategories/nautilus', '101_ObjectCategories/soccer_ball', '101_ObjectCategories/pizza', '101_ObjectCategories/ewer', '101_ObjectCategories/strawberry', '101_ObjectCategories/crab', '101_ObjectCategories/octopus', '101_ObjectCategories/wild_cat', '101_ObjectCategories/anchor']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sPgn_Wq-HGnC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for c, category in enumerate(categories):\n",
        "    images = [os.path.join(dp, f) for dp, dn, filenames \n",
        "              in os.walk(category) for f in filenames \n",
        "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
        "    counter=0\n",
        "    validatin_ratio=0.2\n",
        "    for img_path in images:\n",
        "      counter+=1\n",
        "      dest='train'\n",
        "      if counter>(1-validatin_ratio)*len(images): dest='validation'\n",
        "      spl=img_path.split('/');\n",
        "      move(img_path,dest+os.sep+spl[1]+os.sep+spl[2])\n",
        "\n",
        "# count the number of classes\n",
        "num_classes = len(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2QCMVoxIiw_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dimensions of our images.\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "\n",
        "# number of epochs to train top model\n",
        "epochs = 30\n",
        "# batch size used by flow_from_directory and predict_generator\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8rO6KyOgdOt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_bottlebeck_features():\n",
        "    # build the VGG16 network\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "#     model = applications.ResNet50(include_top=False, weights='imagenet')\n",
        "    \n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "    print(len(generator.filenames))\n",
        "    print(generator.class_indices)\n",
        "    print(len(generator.class_indices))\n",
        "\n",
        "    nb_train_samples = len(generator.filenames)\n",
        "    num_classes = len(generator.class_indices)\n",
        "\n",
        "    predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
        "\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, predict_size_train)\n",
        "\n",
        "    np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "    nb_validation_samples = len(generator.filenames)\n",
        "\n",
        "    predict_size_validation = int(\n",
        "        math.ceil(nb_validation_samples / batch_size))\n",
        "\n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, predict_size_validation)\n",
        "\n",
        "    np.save('bottleneck_features_validation.npy',\n",
        "            bottleneck_features_validation)\n",
        "    print(predict_size_validation)\n",
        "    print(predict_size_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b0KJXyiHuIuJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "=================================================="
      ]
    },
    {
      "metadata": {
        "id": "YZRLyhE7uFou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbgatymzUpPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt    \n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "class ConfusionMatrixPlotter(Callback):\n",
        "    \"\"\"Plot the confusion matrix on a graph and update after each epoch\n",
        "    # Arguments\n",
        "        X_val: The input values \n",
        "        Y_val: The expected output values\n",
        "        classes: The categories as a list of string names\n",
        "        normalize: True - normalize to [0,1], False - keep as is\n",
        "        cmap: Specify matplotlib colour map\n",
        "        title: Graph Title\n",
        "    \"\"\"\n",
        "    def __init__(self, X_val, Y_val, classes, normalize=False, cmap=plt.cm.Blues, title='Confusion Matrix'):\n",
        "        self.X_val = X_val\n",
        "        self.Y_val = Y_val\n",
        "        self.title = title\n",
        "        self.classes = classes\n",
        "        self.normalize = normalize\n",
        "        self.cmap = cmap\n",
        "        plt.ion()\n",
        "        #plt.show()\n",
        "        plt.figure(figsize=(10,10))\n",
        "\n",
        "        plt.title(self.title)\n",
        "        \n",
        "        \n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        pass\n",
        "      \n",
        "    def cm_analysis(self, y_true, y_pred, labels, ymap=None, figsize=(10,10)):\n",
        "        \"\"\"\n",
        "        Generate matrix plot of confusion matrix with pretty annotations.\n",
        "        The plot image is saved to disk.\n",
        "        args: \n",
        "          y_true:    true label of the data, with shape (nsamples,)\n",
        "          y_pred:    prediction of the data, with shape (nsamples,)\n",
        "          filename:  filename of figure file to save\n",
        "          labels:    string array, name the order of class labels in the confusion matrix.\n",
        "                     use `clf.classes_` if using scikit-learn models.\n",
        "                     with shape (nclass,).\n",
        "          ymap:      dict: any -> string, length == nclass.\n",
        "                     if not None, map the labels & ys to more understandable strings.\n",
        "                     Caution: original y_true, y_pred and labels must align.\n",
        "          figsize:   the size of the figure plotted.\n",
        "        \"\"\"\n",
        "        if ymap is not None:\n",
        "            y_pred = [ymap[yi] for yi in y_pred]\n",
        "            y_true = [ymap[yi] for yi in y_true]\n",
        "            labels = [ymap[yi] for yi in labels]\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "        cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "        cm_perc = cm / cm_sum.astype(float) * 100\n",
        "        annot = np.empty_like(cm).astype(str)\n",
        "        nrows, ncols = cm.shape\n",
        "        for i in range(nrows):\n",
        "            for j in range(ncols):\n",
        "                c = cm[i, j]\n",
        "                p = cm_perc[i, j]\n",
        "                if i == j:\n",
        "                    s = cm_sum[i]\n",
        "                    annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "                elif c == 0:\n",
        "                    annot[i, j] = ''\n",
        "                else:\n",
        "                    annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "        cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "        cm.index.name = 'Actual'\n",
        "        cm.columns.name = 'Predicted'\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
        "#         plt.savefig(filename)\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "      \n",
        "        plt.clf()\n",
        "        pred = self.model.predict(self.X_val)\n",
        "        max_pred = np.argmax(pred, axis=1)\n",
        "        max_y = np.argmax(self.Y_val, axis=1)\n",
        "\n",
        "        sess = tf.Session()\n",
        "        img_d_summary_dir = os.path.join(\"/log\", \"summaries\", \"img\")\n",
        "        img_d_summary_writer = tf.summary.FileWriter(img_d_summary_dir,sess.graph)\n",
        "        img_d_summary = plot_confusion_matrix(max_y, max_pred, self.classes, tensor_name='dev/cm')\n",
        "        img_d_summary_writer.add_summary(img_d_summary, epoch)\n",
        "        \n",
        "# #         self.cm_analysis(self.Y_val,max_y,\"test\")\n",
        "#         cnf_mat = confusion_matrix(max_y, max_pred)\n",
        "   \n",
        "#         if self.normalize:\n",
        "#             cnf_mat = cnf_mat.astype('float') / cnf_mat.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "#         thresh = cnf_mat.max() / 2.\n",
        "#         for i, j in itertools.product(range(cnf_mat.shape[0]), range(cnf_mat.shape[1])):\n",
        "#             plt.text(j, i, cnf_mat[i, j],                                          \n",
        "#                          horizontalalignment=\"center\",\n",
        "#                          color=\"white\" if cnf_mat[i, j] > thresh else \"black\")\n",
        "\n",
        "#         plt.imshow(cnf_mat, interpolation='nearest', cmap=self.cmap)\n",
        "\n",
        "#         # Labels\n",
        "#         tick_marks = np.arange(len(self.classes))\n",
        "#         plt.xticks(tick_marks, self.classes, rotation=45)\n",
        "#         plt.yticks(tick_marks, self.classes)\n",
        "\n",
        "#         plt.colorbar()\n",
        "                                                                                                         \n",
        "#         plt.tight_layout()                                                    \n",
        "#         plt.ylabel('True label')                                              \n",
        "#         plt.xlabel('Predicted label')                                         \n",
        "#         #plt.draw()\n",
        "#         plt.show()\n",
        "#         plt.pause(0.001)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZalnKdsSM326",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from textwrap import wrap\n",
        "import re\n",
        "import itertools\n",
        "import tfplot\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(correct_labels, predict_labels, labels, title='Confusion matrix', tensor_name = 'MyFigure/image', normalize=False):\n",
        "  ''' \n",
        "  Parameters:\n",
        "      correct_labels                  : These are your true classification categories.\n",
        "      predict_labels                  : These are you predicted classification categories\n",
        "      labels                          : This is a lit of labels which will be used to display the axix labels\n",
        "      title='Confusion matrix'        : Title for your matrix\n",
        "      tensor_name = 'MyFigure/image'  : Name for the output summay tensor\n",
        "\n",
        "  Returns:\n",
        "      summary: TensorFlow summary \n",
        "\n",
        "  Other itema to note:\n",
        "      - Depending on the number of category and the data , you may have to modify the figzie, font sizes etc. \n",
        "      - Currently, some of the ticks dont line up due to rotations.\n",
        "  '''\n",
        "  cm = confusion_matrix(correct_labels, predict_labels, labels=labels)\n",
        "  if normalize:\n",
        "      cm = cm.astype('float')*10 / cm.sum(axis=1)[:, np.newaxis]\n",
        "      cm = np.nan_to_num(cm, copy=True)\n",
        "      cm = cm.astype('int')\n",
        "\n",
        "  np.set_printoptions(precision=2)\n",
        "  ###fig, ax = matplotlib.figure.Figure()\n",
        "\n",
        "  fig = matplotlib.figure.Figure(figsize=(7, 7), dpi=320, facecolor='w', edgecolor='k')\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  im = ax.imshow(cm, cmap='Oranges')\n",
        "\n",
        "  classes = [re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ', x) for x in labels]\n",
        "  classes = ['\\n'.join(wrap(l, 40)) for l in classes]\n",
        "\n",
        "  tick_marks = np.arange(len(classes))\n",
        "\n",
        "  ax.set_xlabel('Predicted', fontsize=7)\n",
        "  ax.set_xticks(tick_marks)\n",
        "  c = ax.set_xticklabels(classes, fontsize=4, rotation=-90,  ha='center')\n",
        "  ax.xaxis.set_label_position('bottom')\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ax.set_ylabel('True Label', fontsize=7)\n",
        "  ax.set_yticks(tick_marks)\n",
        "  ax.set_yticklabels(classes, fontsize=4, va ='center')\n",
        "  ax.yaxis.set_label_position('left')\n",
        "  ax.yaxis.tick_left()\n",
        "\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      ax.text(j, i, format(cm[i, j], 'd') if cm[i,j]!=0 else '.', horizontalalignment=\"center\", fontsize=6, verticalalignment='center', color= \"black\")\n",
        "  fig.set_tight_layout(True)\n",
        "  summary = tfplot.figure.to_summary(fig, tag=tensor_name)\n",
        "  return summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6vH8Bj3uNfc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "=================================================="
      ]
    },
    {
      "metadata": {
        "id": "FTPTfuJuh6lZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_top_model():\n",
        "    datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
        "    generator_top = datagen_top.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "    nb_train_samples = len(generator_top.filenames)\n",
        "    num_classes = len(generator_top.class_indices)\n",
        "\n",
        "    # save the class indices to user later in predictions\n",
        "    np.save('class_indices.npy', generator_top.class_indices)\n",
        "\n",
        "    # load the bottleneck features saved earlier\n",
        "    train_data = np.load('bottleneck_features_train.npy')\n",
        "\n",
        "    # get the class lebels for the training data, in the original order\n",
        "    train_labels = generator_top.classes\n",
        "\n",
        "    # https://github.com/fchollet/keras/issues/3467\n",
        "    # convert the training labels to categorical vectors\n",
        "    train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "\n",
        "    generator_top = datagen_top.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "    nb_validation_samples = len(generator_top.filenames)\n",
        "\n",
        "    validation_data = np.load('bottleneck_features_validation.npy')\n",
        "\n",
        "    validation_labels = generator_top.classes\n",
        "    validation_labels = to_categorical(\n",
        "        validation_labels, num_classes=num_classes)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.75))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "#     plotter = ConfusionMatrixPlotter(X_val=validation_data, classes=generator_top.classes, Y_val=validation_labels)\n",
        "\n",
        "    \n",
        "\n",
        "    history = model.fit(train_data, train_labels,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(validation_data, validation_labels),callbacks=[tbCallBack])\n",
        "\n",
        "    model.save_weights(top_model_weights_path)\n",
        "\n",
        "    (eval_loss, eval_accuracy) = model.evaluate(\n",
        "        validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "    print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
        "    print(\"[INFO] Loss: {}\".format(eval_loss))\n",
        "\n",
        "    plt.figure(1)\n",
        "\n",
        "    # summarize history for accuracy\n",
        "\n",
        "    plt.subplot(211)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "    # summarize history for loss\n",
        "\n",
        "    plt.subplot(212)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ZlpyHhhh6Wm",
        "colab_type": "code",
        "outputId": "9b0c606d-058c-4df4-c70b-5f9ede1b9df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "save_bottlebeck_features()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 5s 0us/step\n",
            "Found 7280 images belonging to 102 classes.\n",
            "7280\n",
            "{'BACKGROUND_Google': 0, 'Faces': 1, 'Faces_easy': 2, 'Leopards': 3, 'Motorbikes': 4, 'accordion': 5, 'airplanes': 6, 'anchor': 7, 'ant': 8, 'barrel': 9, 'bass': 10, 'beaver': 11, 'binocular': 12, 'bonsai': 13, 'brain': 14, 'brontosaurus': 15, 'buddha': 16, 'butterfly': 17, 'camera': 18, 'cannon': 19, 'car_side': 20, 'ceiling_fan': 21, 'cellphone': 22, 'chair': 23, 'chandelier': 24, 'cougar_body': 25, 'cougar_face': 26, 'crab': 27, 'crayfish': 28, 'crocodile': 29, 'crocodile_head': 30, 'cup': 31, 'dalmatian': 32, 'dollar_bill': 33, 'dolphin': 34, 'dragonfly': 35, 'electric_guitar': 36, 'elephant': 37, 'emu': 38, 'euphonium': 39, 'ewer': 40, 'ferry': 41, 'flamingo': 42, 'flamingo_head': 43, 'garfield': 44, 'gerenuk': 45, 'gramophone': 46, 'grand_piano': 47, 'hawksbill': 48, 'headphone': 49, 'hedgehog': 50, 'helicopter': 51, 'ibis': 52, 'inline_skate': 53, 'joshua_tree': 54, 'kangaroo': 55, 'ketch': 56, 'lamp': 57, 'laptop': 58, 'llama': 59, 'lobster': 60, 'lotus': 61, 'mandolin': 62, 'mayfly': 63, 'menorah': 64, 'metronome': 65, 'minaret': 66, 'nautilus': 67, 'octopus': 68, 'okapi': 69, 'pagoda': 70, 'panda': 71, 'pigeon': 72, 'pizza': 73, 'platypus': 74, 'pyramid': 75, 'revolver': 76, 'rhino': 77, 'rooster': 78, 'saxophone': 79, 'schooner': 80, 'scissors': 81, 'scorpion': 82, 'sea_horse': 83, 'snoopy': 84, 'soccer_ball': 85, 'stapler': 86, 'starfish': 87, 'stegosaurus': 88, 'stop_sign': 89, 'strawberry': 90, 'sunflower': 91, 'tick': 92, 'trilobite': 93, 'umbrella': 94, 'watch': 95, 'water_lilly': 96, 'wheelchair': 97, 'wild_cat': 98, 'windsor_chair': 99, 'wrench': 100, 'yin_yang': 101}\n",
            "102\n",
            "Found 1864 images belonging to 102 classes.\n",
            "15\n",
            "57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P4JoYL6nPpMA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F0QmdoyIh6NV",
        "colab_type": "code",
        "outputId": "bd47d2a2-c466-4167-c905-c39f252a1261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1611
        }
      },
      "cell_type": "code",
      "source": [
        "train_top_model()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7280 images belonging to 102 classes.\n",
            "Found 1864 images belonging to 102 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 7280 samples, validate on 1864 samples\n",
            "Epoch 1/30\n",
            "7280/7280 [==============================] - 3s 367us/step - loss: 4.7002 - acc: 0.3089 - val_loss: 2.3786 - val_acc: 0.5166\n",
            "Epoch 2/30\n",
            "7280/7280 [==============================] - 2s 246us/step - loss: 2.4057 - acc: 0.4587 - val_loss: 1.6598 - val_acc: 0.6508\n",
            "Epoch 3/30\n",
            "7280/7280 [==============================] - 2s 243us/step - loss: 1.9491 - acc: 0.5352 - val_loss: 1.3135 - val_acc: 0.7221\n",
            "Epoch 4/30\n",
            "7280/7280 [==============================] - 2s 249us/step - loss: 1.6278 - acc: 0.5960 - val_loss: 1.0987 - val_acc: 0.7344\n",
            "Epoch 5/30\n",
            "7280/7280 [==============================] - 2s 252us/step - loss: 1.4648 - acc: 0.6210 - val_loss: 0.9185 - val_acc: 0.7833\n",
            "Epoch 6/30\n",
            "7280/7280 [==============================] - 2s 242us/step - loss: 1.2616 - acc: 0.6622 - val_loss: 0.8124 - val_acc: 0.8036\n",
            "Epoch 7/30\n",
            "7280/7280 [==============================] - 2s 259us/step - loss: 1.1112 - acc: 0.6979 - val_loss: 0.7500 - val_acc: 0.8106\n",
            "Epoch 8/30\n",
            "7280/7280 [==============================] - 2s 243us/step - loss: 1.0730 - acc: 0.7059 - val_loss: 0.7033 - val_acc: 0.8203\n",
            "Epoch 9/30\n",
            "7280/7280 [==============================] - 2s 257us/step - loss: 0.9470 - acc: 0.7308 - val_loss: 0.6649 - val_acc: 0.8267\n",
            "Epoch 10/30\n",
            "7280/7280 [==============================] - 2s 249us/step - loss: 0.9266 - acc: 0.7357 - val_loss: 0.6510 - val_acc: 0.8342\n",
            "Epoch 11/30\n",
            "7280/7280 [==============================] - 2s 240us/step - loss: 0.8277 - acc: 0.7621 - val_loss: 0.6419 - val_acc: 0.8278\n",
            "Epoch 12/30\n",
            "7280/7280 [==============================] - 2s 245us/step - loss: 0.7962 - acc: 0.7694 - val_loss: 0.6065 - val_acc: 0.8273\n",
            "Epoch 13/30\n",
            "7280/7280 [==============================] - 2s 243us/step - loss: 0.7220 - acc: 0.7890 - val_loss: 0.5783 - val_acc: 0.8433\n",
            "Epoch 14/30\n",
            "7280/7280 [==============================] - 2s 246us/step - loss: 0.7237 - acc: 0.7901 - val_loss: 0.5541 - val_acc: 0.8466\n",
            "Epoch 15/30\n",
            "7280/7280 [==============================] - 2s 246us/step - loss: 0.6736 - acc: 0.8005 - val_loss: 0.5730 - val_acc: 0.8342\n",
            "Epoch 16/30\n",
            "7280/7280 [==============================] - 2s 246us/step - loss: 0.6410 - acc: 0.8071 - val_loss: 0.5735 - val_acc: 0.8369\n",
            "Epoch 17/30\n",
            "7280/7280 [==============================] - 2s 249us/step - loss: 0.6057 - acc: 0.8165 - val_loss: 0.5210 - val_acc: 0.8530\n",
            "Epoch 18/30\n",
            "7280/7280 [==============================] - 2s 242us/step - loss: 0.5886 - acc: 0.8154 - val_loss: 0.5318 - val_acc: 0.8471\n",
            "Epoch 19/30\n",
            "7280/7280 [==============================] - 2s 254us/step - loss: 0.5450 - acc: 0.8323 - val_loss: 0.5169 - val_acc: 0.8519\n",
            "Epoch 20/30\n",
            "7280/7280 [==============================] - 2s 247us/step - loss: 0.5393 - acc: 0.8299 - val_loss: 0.5036 - val_acc: 0.8573\n",
            "Epoch 21/30\n",
            "7280/7280 [==============================] - 2s 243us/step - loss: 0.4957 - acc: 0.8438 - val_loss: 0.4989 - val_acc: 0.8648\n",
            "Epoch 22/30\n",
            "7280/7280 [==============================] - 2s 245us/step - loss: 0.4845 - acc: 0.8497 - val_loss: 0.4987 - val_acc: 0.8611\n",
            "Epoch 23/30\n",
            "7280/7280 [==============================] - 2s 255us/step - loss: 0.5068 - acc: 0.8387 - val_loss: 0.5544 - val_acc: 0.8460\n",
            "Epoch 24/30\n",
            "7280/7280 [==============================] - 2s 244us/step - loss: 0.4688 - acc: 0.8497 - val_loss: 0.5597 - val_acc: 0.8433\n",
            "Epoch 25/30\n",
            "7280/7280 [==============================] - 2s 241us/step - loss: 0.4394 - acc: 0.8571 - val_loss: 0.5600 - val_acc: 0.8514\n",
            "Epoch 26/30\n",
            "7280/7280 [==============================] - 2s 256us/step - loss: 0.4487 - acc: 0.8567 - val_loss: 0.5582 - val_acc: 0.8433\n",
            "Epoch 27/30\n",
            "7280/7280 [==============================] - 2s 240us/step - loss: 0.4574 - acc: 0.8536 - val_loss: 0.5254 - val_acc: 0.8594\n",
            "Epoch 28/30\n",
            "7280/7280 [==============================] - 2s 240us/step - loss: 0.4423 - acc: 0.8578 - val_loss: 0.5214 - val_acc: 0.8487\n",
            "Epoch 29/30\n",
            "7280/7280 [==============================] - 2s 242us/step - loss: 0.4350 - acc: 0.8613 - val_loss: 0.5190 - val_acc: 0.8589\n",
            "Epoch 30/30\n",
            "7280/7280 [==============================] - 2s 245us/step - loss: 0.4275 - acc: 0.8615 - val_loss: 0.5572 - val_acc: 0.8444\n",
            "1864/1864 [==============================] - 0s 84us/step\n",
            "[INFO] accuracy: 84.44%\n",
            "[INFO] Loss: 0.5572448282266763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4gD-r2P5M5BF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}